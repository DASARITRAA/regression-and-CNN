{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = mnist.load_data("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(X_test[0],cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing data to bring in range 0 to 1 from 0 to 255\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1,X_train.shape[1]*X_train.shape[2])\n",
    "X_test = X_test.reshape(-1,X_test.shape[1]*X_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #Flattened the images from 28x28 to 784 to feed to neural network neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_test = np_utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() #Making a feed-forward artificial neural network with sequential layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers and activations\n",
    "model.add(Dense(128,activation='relu',input_shape=(784,)))\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "#Categorical crossentropy is used to define error for multiple classes (0 to 9 in this case)\n",
    "#Adam optimizer uses a combination of RMSProp and Gradient Descent Optimization technique\n",
    "#We are judging the model on its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 32s 660us/step - loss: 1.2457 - acc: 0.6047 - val_loss: 0.5048 - val_acc: 0.8678\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.3830 - acc: 0.8956 - val_loss: 0.2725 - val_acc: 0.9237\n",
      "Epoch 3/40\n",
      "11000/48000 [=====>........................] - ETA: 6s - loss: 0.2725 - acc: 0.9276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Miniconda3\\envs\\py35\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.510321). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "C:\\Users\\user\\Miniconda3\\envs\\py35\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.256178). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.2516 - acc: 0.9299 - val_loss: 0.2126 - val_acc: 0.9411\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.2011 - acc: 0.9438 - val_loss: 0.1828 - val_acc: 0.9494\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 1s 18us/step - loss: 0.1707 - acc: 0.9514 - val_loss: 0.1610 - val_acc: 0.9565\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1444 - acc: 0.9598 - val_loss: 0.1426 - val_acc: 0.9618\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1265 - acc: 0.9639 - val_loss: 0.1364 - val_acc: 0.9621\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 1s 17us/step - loss: 0.1132 - acc: 0.9681 - val_loss: 0.1319 - val_acc: 0.9608\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 0.1004 - acc: 0.9719 - val_loss: 0.1273 - val_acc: 0.9633\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0927 - acc: 0.9736 - val_loss: 0.1181 - val_acc: 0.9659\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0827 - acc: 0.9767 - val_loss: 0.1153 - val_acc: 0.9663\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0733 - acc: 0.9801 - val_loss: 0.1086 - val_acc: 0.9685\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0674 - acc: 0.9813 - val_loss: 0.1059 - val_acc: 0.9699\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0603 - acc: 0.9835 - val_loss: 0.1052 - val_acc: 0.9692\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0551 - acc: 0.9853 - val_loss: 0.1007 - val_acc: 0.9718\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0508 - acc: 0.9861 - val_loss: 0.1012 - val_acc: 0.9705\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0448 - acc: 0.9884 - val_loss: 0.0987 - val_acc: 0.9724\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0418 - acc: 0.9889 - val_loss: 0.1007 - val_acc: 0.9723\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 1s 20us/step - loss: 0.0378 - acc: 0.9901 - val_loss: 0.1012 - val_acc: 0.9713\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0346 - acc: 0.9912 - val_loss: 0.0965 - val_acc: 0.9722\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0308 - acc: 0.9925 - val_loss: 0.1004 - val_acc: 0.9720\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0280 - acc: 0.9932 - val_loss: 0.0969 - val_acc: 0.9734\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0249 - acc: 0.9945 - val_loss: 0.1024 - val_acc: 0.9721\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0243 - acc: 0.9942 - val_loss: 0.0977 - val_acc: 0.9736\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0211 - acc: 0.9953 - val_loss: 0.0993 - val_acc: 0.9726\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.0191 - acc: 0.9961 - val_loss: 0.0996 - val_acc: 0.9725\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0168 - acc: 0.9968 - val_loss: 0.0988 - val_acc: 0.9722\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0150 - acc: 0.9974 - val_loss: 0.0991 - val_acc: 0.9732\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0141 - acc: 0.9976 - val_loss: 0.1017 - val_acc: 0.9723\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0127 - acc: 0.9980 - val_loss: 0.0987 - val_acc: 0.9743\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 1s 24us/step - loss: 0.0108 - acc: 0.9982 - val_loss: 0.1046 - val_acc: 0.9733\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0102 - acc: 0.9984 - val_loss: 0.1033 - val_acc: 0.9733\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 1s 21us/step - loss: 0.0093 - acc: 0.9988 - val_loss: 0.1018 - val_acc: 0.9741\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0083 - acc: 0.9989 - val_loss: 0.1045 - val_acc: 0.9737\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0074 - acc: 0.9992 - val_loss: 0.1062 - val_acc: 0.9736\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.0070 - acc: 0.9993 - val_loss: 0.1078 - val_acc: 0.9739\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.0071 - acc: 0.9992 - val_loss: 0.1071 - val_acc: 0.9747\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0056 - acc: 0.9995 - val_loss: 0.1087 - val_acc: 0.9741\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.0050 - acc: 0.9997 - val_loss: 0.1087 - val_acc: 0.9742\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 1s 22us/step - loss: 0.0045 - acc: 0.9997 - val_loss: 0.1089 - val_acc: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a609d59c18>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model using the training data\n",
    "model.fit(X_train,Y_train,batch_size=1000,epochs=40,validation_split=0.2)\n",
    "#All the above parameters in fit function are hyperparameters, change them and experiment with them to see what different results can be found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating test accuracy\n",
    "import numpy as np\n",
    "total = len(X_test)\n",
    "Y_pred = model.predict(X_test)\n",
    "corr=0\n",
    "for i in range(len(X_test)):\n",
    "    if np.argmax(Y_pred[i]) == np.argmax(Y_test[i]):\n",
    "        corr+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = corr/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9759"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#working of argmax\n",
    "np.argmax(Y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
